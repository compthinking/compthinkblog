---
title: Movie Live-blog - The Creator
date: 2023-12-30
tags:
  - machine-learning
  - artificial-inteligence
  - ai-doom
show_tags: true
show_bib: true
type: draft
---

(I'm going to watch it and write as a I watch
I need to watch more AI movies, maybe all of them. since society is becoming so interested and it will behlp me to scope out what people are really worreied about.)

## Setup
So it seems to start with a standard idea of an Artificial Intelligence launching nuclear weapons at human beings and the ensuing war. What is immediately different about this story is that *only America* seems to be targeted and to keep the war going. A single nuclear weapon detonates in Los Angeles and then the United State, and perhaps it's Western Allies, carry out a war for decades trying to ban, erradicate all AI systems, but nations in Asia follow a different path and continue to develop AI and sentient robots. 

They don't get too specific about what "AI" means but they connect it strongly to full autonomous, thinking, feeling robots which are seen to be alive and treated as almost equal peers in society. Given this premise, the story begins with the very plausible scenario of American societal and military objectives of "the enemy" carrying through every aspect of life. Since the AI's aren't real, and since they are a threat due to the nuke, they must be hunted down and destroyed. If the problem is bad guys attacking you, the solution is kill all the bad guys, and the problem will go away. The fact this has never worked in all of human history is, I assume, going to be one of the main moral lessons of the movie. We shall see.

## The Performances

## The World
Very satisfying as a more realistic Blade Runner-esque future, updated for our modern world. They don't go overboard with anything in the world, the politics, the technology. Everything is a few steps ahead but the world itself is very reconizable to the modern mind.

The acting is quite good, the characters felt believable and true for the most part. 

The restraint shown in special effects was quite satisfying. It made things feel real but also realistic. The holograms weren't perfect, the flat screen pictures were dirty and creased. The robot cranium effect was elegant and simple, showing us who was a robot, but revealing a beautiful mechanism that seemed poetic. The behaviour of the simulants as just as distractible, tired, cautious as humans was refreshing. And the spiritual aspect of the sims was quite interesting. There seemed to even be some argument about an Asian vs. Western approach to metaphysics, a respect for these new beings who are somehow more centred, more peaceful, and maybe even wiser than the humans that created them about spiritual matters. 


## The Conclusion
Ok that was beautifully done. It comes back to the essential truth of most suffering in the world, suffering arises from not treating people as people. In the world of this movie, Robot AI's have reached the level where they have the complexity of mind, even soul, that makes them people. So objectifying them and trying to wipe them out is wrong. While the topic is AI, it's a perfect allegory for most human conflicts. We are very quick to turn the enemy being fought into inhuman monsters who need to be defeated at all costs. But the costs is always the lives of sentient beings, each one as precious as a whole universe, because each person is a universe, unknowable to anyone else. Maybe that should be how we decide on whether AI should be people or not. When they reach such a level of complexity, subtlety and depth of mind that it is unknowable to any other being, and have their own internal experience, will and feelings that guide them. 

## So Is This Fantasy or Science Fiction?
Some people feel we are close to this now, but I disagree. To be sure, we are approaching the criteria of complexity, that the "mind" of many AI systems is beyond the ability of any other mind to fully understand. This was not true 20 years ago, and even 10 years ago we might feel that a Herculean effort at analysis might allow us to see the source of all behaviours. But for the latest Foundation models this is probably not even theoretically at a detailed level, and not just because of the large amounts of data, but because of the connections within the models.

But even so, these current systems and even emerging ones, are not sentient. 
They are not alive. They do not have their own will. 
Most of them do not even have their own lived experience beyond the training data provided to them.
They certainly do not emotions or feelings. 
(We don't even know how to define that or measure that.)

*At least not right now.*

But all these things are possible, we believe, because we experience them as a result of the very complex Natural Intelligence system encased in our skulls, designed by millions of years of evolution and trained by lived experience and educated by other beings according to our own cultural practices, which themselves are complex protocols evolved over thousands of years.

As far as I can see, everything shown in this movie is possible. The hover bikes and various barges, cars and ships floating with little or no air disturbance seem to me to be the most unrealistic technological aspect of the movie, requiring some new science we aren't aware of yet. But everything else from the AI subtlety, the improvements in robotics, and other tech all seem fairly plausible over the next century. 

## (The missing Thing)
There was one other huge missing incongruity about this near future decades ahead of us, but it doesn't relate to the core topic of the film. That is the lack of any mention of climate change as far as I could tell. As storytellers, I can fully understand not wanting to complicate things further by bringing in another moral aspect to their world. It would be distracting from the core theme. As a Science Fiction story, I guess that the introductory history given at the beginning sets this story up in an alternate world to our own where robotic and AI technology was developed much earlier. So, it's quite possible that other aspects of the world are different as well, and they somewhat smoothly sidestepped our crisis using their more advanced technology before it was too late.

## (On Humanity)
As for the bottomless pit of human cruelty, vengefulness and blindness to our misguided moral certainty shown in the movie motivating the villains in this movie. It's downright realistic and only a bit exaggerated for effect. They gave some nod to difference of opinion even in America, that people had been protesting the War on AI, either for excessive costs or moral reasons. But even the arch villains are doing this for consistent internal reasons, they truly believe in the threat posed by AI and that their only way to survive is to kill it all.  It is exaggerated in this story and has very specific reasons, a nuclear bomb exploding due to human error which is blamed on the AIs and provides the "proof" needed for the existential risk argument. However, this worry about existential risk is a common thread in discussions about AI regulation amongst the media, government and even some academics. I have always said, we have far much more to worry about for the use of AI and any advanced technology in human hands, than in the hypothetical hands of some future, fully sentient AI systems. 

This reasoning on the extrapolations of an exponential curve is a tempting one for any technical or mathematical minded person, and for men in particular. I love ramping up the outcomes to infinity to see what happens. But it's not grounded in reality.

That blindness to practical, grounded life is why we have the climate crisis we have. No one could see past the collapse of existing industries that some curve might show, and allow themselves to imagine a reconfigured world where cooperation and innovation allowed us to avoid the coming climate disaster. We let those extrapolations of existing paths stop us from finding a new path forward. 

Similarly, extrapolating forward existing AI tech and uses lets us bring up all manner of fears, but none of that accounts for the way life really proceeds. The world changes as technology, science and culture change. It all happens at once, together, interacting with each other. We cannot predict how fully sentient, feeling, willful, living AI will arrive and what our world will look like when it does. But we can very clearly predict what human beings with greed, hate, fear, and too much certainty in their hearts, will do with autonomous weapons, with untrammelled data from all sources, with unified control or information, news, and The Truth itself. Regulation and adult, unemotional discussion is needed on these technologies and how society wants to develop them, monitor them and use them. This includes choices to not use them sometimes, as with weapon systems that take the human decision away from killing other human beings.


## Questions
### That other review...
they said "questionable ethics or morality?" what did they mean? Are they taking the AI regulation success to mean something has been decisded on this front?

It seems very pertitent in fact. Are we preblaming this technology for some failure we imagine may happen. Tehre is no expcuses for not favouring human life and reduction of suffering right now, at every moment. Right now most suffering is caused by other people, none of our technologies can take any "responsibility" for it because they have no will to choose what they do, they aren't beings who have decisions, choices, values, responsilibty. Those concepts are reserved for the people who deploy a system in the world.
